---
title:  "Diffusion Model: 用Fooocus生成圖片"
date:   2025-12-04 01:00:00 +0800
categories: ai
tags: [fooocus, diffusion]
---
我們知道使用ai生成圖片，依照這些年的發展，有三種方式。(1)GAN 生成對抗網路、(2)Diffusion Models、(3)LLM生成圖片。今天我們要分享的Fooocus，是屬於第二種。

依照接下來的操作，建議先到github，將[fooocus的colab程式](https://github.com/lllyasviel/Fooocus)複製一份到自己的GoogleDrive來執行。下面接著說明概念和步驟：

## 用Fooocus生圖

說明：
1. FaceSwap: 換臉
2. CPDS: 做動作控制
3. PyraCanny：描邊圖

### 用Images prompt 生成圖
首先來練習換臉，FaceSwap。先上傳一張圖片，在prompt寫出你要圖片中的人物做什麼動作？地點在哪？ai就會依照你的描述來生成圖片。下面是我上傳院長的圖片，然後要他用院長的臉來完成我的promt生圖。
```
A handsome Taiwanese man using a laptop in a cozy coffee shop. Warm ambient lighting, wooden tables, soft window light, relaxed atmosphere, shallow depth of field, realistic skin texture, natural pose, high-resolution photography style.

```
![gen-lin](/assets/images/gen-lin.jpg)

結論：我們可以發現，有點不像！因為ai沒有學過畫這個人，所以畫出來不像是正常的！

### 用ai人再畫一張，就很像
因為你用fooocus畫出來的ai人，當作下一次生圖用的input，這時候因為它畫過這個ai人，所以接下來的人物特徵就會一模一樣。

```
A man standing at the classroom podium, writing on the chalkboard. Bright classroom lighting, wooden desks, clear chalk dust texture, natural pose, realistic style, high detail.
```
![pic2](/assets/images/Screenshot%202025-12-04%20at%2012.01.23 PM.png)

### 用CPDS控制動作
我們再嘗試用這個人臉(設定FaceSwap)，指定這個動作(設定CPDS)。看看效果如何？！

當然，我們必須準備一個動作圖給fooocus參考。我的經驗是，這張圖最好是去背的PNG，圖片中只有動作，這樣生圖比較不會錯誤。另外，圖片尺寸Aspect Radio要調成跟這個原始動作圖的長寬比一致。

這樣，我就得到一張虛擬院長在教室裡跳舞的圖了～
小提醒：prompt最好要寫國籍，不然可能會生成歐洲人

![pic3](/assets/images/fooocus02.png)


## 用PyraCanny描邊
我們拿一張chatGPT生成的圖(帥氣男醫師站在南港展覽館前)，然後放到fooocus請他描邊。stop值設定0.5，看看描邊效果如何？

![描邊](/assets/images/fooocus05.png)

效果不錯！動作、場景都一致。但畢竟不是fooocus自己畫的ai角色，所以描邊結果的人物臉孔會有點不像。

## 結論
- 這是一個diffusion model(fooocus)生成圖片的demo。
- 如果你要創造一個角色，且未來生成圖片都要有這個角色，並且要穩定生成，這方式可考慮。